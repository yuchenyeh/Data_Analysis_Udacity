{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Fraud from Enron Email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yuchen Yeh, November 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives. \n",
    "\n",
    "The aim of this project is to use classification techniques in machine learning to predict person of interest identifier (POIs) based on financial and email data made public as a result of the Enron scandal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Dataset and Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration\n",
    "\n",
    "The features in the data fall into three major types, namely financial features, email features and POI labels:\n",
    "\n",
    "* financial features: ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees'] \n",
    "\n",
    "* email features: ['to_messages', 'email_address', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi'] \n",
    "\n",
    "* POI label: [‘poi’] \n",
    "\n",
    "Important characteristics of this Enron dataset are:\n",
    "\n",
    "* 146 data points (i.e. people)\n",
    "* 21 available features for each person\n",
    "* of 146 people, 18 are identified as POIs\n",
    "* Missing values across all features except the POI label.\n",
    "\n",
    "With only 18 people allocated for POIs, the classification data is unbalanced. This means cross-validation method like Stratified Shuffle Split is important since it makes sure the ratio of POI and non-POI is the same during training and testing. Also, the number of data is relatively small, which means Stratified Shuffle Split combined with Grid Search CV is acceptable to use to have a reasonable training time.\n",
    "\n",
    "\n",
    "\n",
    "#### Outliner identification\n",
    "\n",
    "By looking at two features (“salary” and “bonus”) through a scatterplot, I identified an outlier named TOTAL. This is a spreadsheet artifact and it was therefore removed. Two data points look like potential outliers due to their much larger values but in fact they are valid data : Enron founder  LAY KENNETH L and former CEO SKILLING JEFFREY K made bonuses of at least 5 million dollars, and a salary of over 1 million dollars.\n",
    "\n",
    "Yet another outlier \"THE TRAVEL AGENCY IN THE PARK\" is found by manually scanning the enron61702insiderpay.pdf \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new features \n",
    "\n",
    "Two features are created to understand the percentage of the total emails received or sent is related to POIs:\n",
    "\n",
    "* fraction_from_poi: Fraction of emails received from POIs.\n",
    "* fraction_to_poi: Fraction of emails sent to POIs.\n",
    "\n",
    "In general, POIs send emails to other POIs at a rate higher than the general population. These two features are added to help to improve the classifier's performance, as calculating the fraction of emails related to POIs can add an indication that the person is highly considered to be POSs.\n",
    "\n",
    "\n",
    "#### Intelligently select features \n",
    "\n",
    "In order to decide which features should be included, I consider the whole feature list plus two new added features. I used SelectKBest for feature selection: present the feature scores for all features (k = 'all'), ordered in descending order.\n",
    "\n",
    "<table>\n",
    " <tr>\n",
    "    <td><b>Feature</b></td>\n",
    "    <td><b>Score</b></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>exercised_stock_options</td>\n",
    "    <td>24.82</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>total_stock_value</td>\n",
    "    <td>24.18</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>bonus</td>\n",
    "    <td>20.79</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>salary</td>\n",
    "    <td>18.29</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>fraction_to_poi</td>\n",
    "    <td>16.41</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>deferred_income</td>\n",
    "    <td>11.46</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>long_term_incentive</td>\n",
    "    <td>9.92</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>restricted_stock</td>\n",
    "    <td>9.21</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>total_payments</td>\n",
    "    <td>8.77</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>shared_receipt_with_poi</td>\n",
    "    <td>8.59</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>loan_advances</td>\n",
    "    <td>7.18</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>expenses</td>\n",
    "    <td>6.09</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>from_poi_to_this_person</td>\n",
    "    <td>5.24</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>other</td>\n",
    "    <td>4.19</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>fraction_from_poi</td>\n",
    "    <td>3.13</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>from_this_person_to_poi</td>\n",
    "    <td>2.38</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>director_fees</td>\n",
    "    <td>2.13</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>to_messages</td>\n",
    "    <td>1.65</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>deferral_payments</td>\n",
    "    <td>0.22</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>from_messages</td>\n",
    "    <td>0.17</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>restricted_stock_deferred</td>\n",
    "    <td>0.07</td>\n",
    "  </tr>\n",
    " </table>\n",
    "\n",
    "I see a cutoff when the score dropped from (16.41, 'fraction_to_poi') to \n",
    "(11.46, 'deferred_income').  Therefore, I choose 5 features are associated with ar score of more than 15:\n",
    "\n",
    "* 'poi'\n",
    "* 'salary'\n",
    "* 'bonus'\n",
    "* 'total_stock_value'\n",
    "* 'exercised_stock_options'\n",
    "* 'fraction_to_poi'\n",
    "\n",
    "It is new features 'fraction_to_poi' shows a high score, and another new feature 'fraction_from_poi' is less relevant.\n",
    "\n",
    "\n",
    "#### Properly scale features \n",
    "I scaled all features using the scikit-learn MinMaxScaler to avoid problems caused by different units in the dataset. However, the algorithms I used (decision tree and naive Bayes classifiers) do not need feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick and Tune an Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested with 2 algorithms to see which one performs the best:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The classification report for GaussianNB is provided below.\n",
    "\n",
    "GaussianNB(priors=None)\n",
    "\tAccuracy: 0.85629\t<b> Precision: 0.49545\tRecall: 0.32650\t </b> F1: 0.39361\tF2: 0.35040\n",
    "\tTotal predictions: 14000\tTrue positives:  653\tFalse positives:  665\tFalse negatives: 1347\tTrue negatives: 11335"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree:\n",
    "In order to achieve better performance for the decision tree algorithm, I performed parameter tuning. Out all of the parameters available, I decided to tune min_samples_split. Min_samples_split is the minimum number of samples is required to split an internal node, and it affects if the decision tree classifier is overfitting. In general, a bigger value of min_samples_split draws a simpler boundary and provides a better accuracy.\n",
    "\n",
    "I used GridSearchCV to identify the best parameter for min_samples_split in a range between 2 (default) and 50.  The best one is 14 and I, therefore, used this value to compute the decision tree classifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The classification report for decision tree is provided below.\n",
    " \n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=14, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "\tAccuracy: 0.80650\t<b> Precision: 0.29960\tRecall: 0.26500\t</b> F1: 0.28124\tF2: 0.27127\n",
    "\tTotal predictions: 14000\tTrue positives:  530\tFalse positives: 1239\tFalse negatives: 1470\tTrue negatives: 10761\n",
    " \n",
    "\n",
    "Feature importance:\n",
    "* 'salary' importance is 0.168042010503\n",
    "* 'bonus' importance is 0.130932733183\n",
    "* 'total_stock_value' importance is 0.421015598727\n",
    "* 'exercised_stock_options' importance is 0.132033008252\n",
    "* 'fraction_to_poi' importance is 0.147976649335\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, I selected GaussianNB as the algorithm because it performed the better in terms of precision and recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Enron dataset, only 18 data points are POIs. Having imbalanced classes introduces some special challenges in accuracy. The accuracy metric is used to identify numbers of items in a class is labelled correctly. Therefore, accuracy is not a good evaluation metric.\n",
    "\n",
    "I used precision and recall to evaluate algorithm performance. When tester.py is used to evaluate performance for the chosen algorithm GaussianNB, precision is 0.49545 and recall is 0.32650, both are at least 0.3. The result shows precison for GaussianNB is quite good, which means whenever a POI gets flagged in my test set it is likely to a real POI. However recall is slightly low, and it shows I sometimes miss real POIs.\n",
    "\n",
    "\n",
    "\n",
    "Cross-validation is to make sure the data is generalized beyond the dataset used to train it, in order to avoid this situation overfitting. A model sometimes just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. \n",
    "\n",
    "I used the provided StratifiedShuffleSplit method (n_iter=10000, test_size=0.3, random_state=0)) to validate the chosen algorithm GaussianNB. It is notable that the returned evaluation metrics are the same: precision is 0.49545 and recall is 0.32650. This means we have validated the performance metrics, precision and recall, for the chosen algorithm.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
